{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DywmMcxTLHz8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Titanic dataset\n",
        "df = pd.read_csv('/content/Titanic-Dataset.csv')"
      ],
      "metadata": {
        "id": "hzvKR9MkMdLc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Handle Missing Values\n",
        "# Check for missing values\n",
        "print(\"Missing values before handling:\\n\", df.isnull().sum())\n",
        "\n",
        "# Fill missing values for 'Age' with the median value\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "\n",
        "# Fill missing values for 'Embarked' with the mode value\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop the 'Cabin' column since it has many missing values\n",
        "df.drop(columns=['Cabin'], inplace=True)\n",
        "\n",
        "# Fill missing 'Fare' values with the median\n",
        "df['Fare'].fillna(df['Fare'].median(), inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqXs4OgTMlx6",
        "outputId": "cffbb16c-59cc-44c9-886b-4ddc403c6455"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before handling:\n",
            " PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Handle Outliers\n",
        "# You can implement outlier handling logic if needed\n",
        "def handle_outliers(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Cap the outliers\n",
        "    df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])\n",
        "    df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])\n",
        "\n",
        "# Handle outliers for 'Age' and 'Fare'\n",
        "handle_outliers(df, 'Age')\n",
        "handle_outliers(df, 'Fare')\n"
      ],
      "metadata": {
        "id": "cgbtZzYaMrKi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Normalize or Scale Features\n",
        "# Encode categorical variables\n",
        "df['Sex'] = LabelEncoder().fit_transform(df['Sex'])\n",
        "df = pd.get_dummies(df, columns=['Embarked'])\n",
        "\n",
        "# Select numerical columns for scaling\n",
        "num_cols = ['Age', 'Fare', 'Parch', 'SibSp']\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the numerical columns\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n"
      ],
      "metadata": {
        "id": "nGw5pRzjMzzM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Split the Data into Training and Testing Sets\n",
        "# Define the target variable and feature set\n",
        "X = df.drop(columns=['Survived', 'Name', 'Ticket', 'PassengerId'])\n",
        "y = df['Survived']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Output the results\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)\n",
        "print(\"Training set labels shape:\", y_train.shape)\n",
        "print(\"Testing set labels shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Msyu-Xf4M3EE",
        "outputId": "4b1649d4-7314-463d-a2d2-5cd019a75db5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (712, 9)\n",
            "Testing set shape: (179, 9)\n",
            "Training set labels shape: (712,)\n",
            "Testing set labels shape: (179,)\n"
          ]
        }
      ]
    }
  ]
}